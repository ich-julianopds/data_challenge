{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_challenge_parte_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOsEHYNGs/i5lsDlWuYc93k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ich-julianopds/data_challenge/blob/main/data_challenge_parte_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "737LUafXCU0S"
      },
      "source": [
        "# **Análise de Sentimentos no Twitter**\n",
        "Esta é a segunda parte do projeto de Análise de Sentimentos no Twitter.\n",
        "À princípio iria utilizar os dados armazenados na coleta do Mongo DB do processo anterior, porém, devido à imprevistos de tempo, acabei tendo que fazer o desafio nos dois últimos dias, por isso decidi utilizar um dataset do Kaggle já parcialmente tratado, sendo necessárias apenas modificações menores, com a limpeza e equalização dos dados, e como sabemos, é uma das partes que mais demanda tempo. Assim,  segue abaixo a sequência do projeto:\n",
        "\n",
        "Como mencionado acima, os dados para uso foram do Kaggle, referentes à opinião de clientes em relação à uma companhia aérea americana, assim, o dataset está em inglês.\n",
        "Me baseei também em um projeto do cientista de dados Odemir Depieri Jr.\n",
        "Este projeto pode ser de ajuda por exemplo, para que as empresas possam fazer análise de opinião, satisfação, perfil de clientes, etc.\n",
        "Utilizaremos como biblioteca principal o NLTK, que trata do processamento de Linguagem Natural."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVQU-y28JF6E",
        "outputId": "8b2d1d2c-c87c-4627-8341-d91bd1f2f427"
      },
      "source": [
        "pip install contractions"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.0.52-py2.py3-none-any.whl (7.2 kB)\n",
            "Collecting textsearch>=0.0.21\n",
            "  Downloading textsearch-0.0.21-py2.py3-none-any.whl (7.5 kB)\n",
            "Collecting anyascii\n",
            "  Downloading anyascii-0.3.0-py3-none-any.whl (284 kB)\n",
            "\u001b[K     |████████████████████████████████| 284 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting pyahocorasick\n",
            "  Downloading pyahocorasick-1.4.2.tar.gz (321 kB)\n",
            "\u001b[K     |████████████████████████████████| 321 kB 49.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
            "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.2-cp37-cp37m-linux_x86_64.whl size=85446 sha256=f9b1bb75083828ee7b57e8671e537cf6507baefbb1f65ff1777cb2e624b1b021\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/19/a6/8f363d9939162782bb8439d886469756271abc01f76fbd790f\n",
            "Successfully built pyahocorasick\n",
            "Installing collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.0 contractions-0.0.52 pyahocorasick-1.4.2 textsearch-0.0.21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38vAvtFRAqlS"
      },
      "source": [
        "# Importação das bibliotecas necessárias\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import re\n",
        "import contractions"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzwYhWxUI-PE"
      },
      "source": [
        "df_first = pd.read_csv('/content/Tweets.csv')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "P038HHxmKBP9",
        "outputId": "62790aed-db78-460d-b2a8-0bd4f78bb0b9"
      },
      "source": [
        "# Verificar as entradas\n",
        "\n",
        "df_first.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>570306133677760513</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cairdin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:35:52 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>570301130888122368</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:59 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>570301083672813571</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6837</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yvonnalynn</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:48 -0800</td>\n",
              "      <td>Lets Play</td>\n",
              "      <td>Central Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>570301031407624196</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:36 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>570300817074462722</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:14:45 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             tweet_id  ...               user_timezone\n",
              "0  570306133677760513  ...  Eastern Time (US & Canada)\n",
              "1  570301130888122368  ...  Pacific Time (US & Canada)\n",
              "2  570301083672813571  ...  Central Time (US & Canada)\n",
              "3  570301031407624196  ...  Pacific Time (US & Canada)\n",
              "4  570300817074462722  ...  Pacific Time (US & Canada)\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzKJzthRKDHT",
        "outputId": "da82914a-28ea-439f-8600-1c6c5dbf958a"
      },
      "source": [
        "# 1460 linhas x 15 colunas\n",
        "df_first.describe"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.describe of                  tweet_id  ...               user_timezone\n",
              "0      570306133677760513  ...  Eastern Time (US & Canada)\n",
              "1      570301130888122368  ...  Pacific Time (US & Canada)\n",
              "2      570301083672813571  ...  Central Time (US & Canada)\n",
              "3      570301031407624196  ...  Pacific Time (US & Canada)\n",
              "4      570300817074462722  ...  Pacific Time (US & Canada)\n",
              "...                   ...  ...                         ...\n",
              "14635  569587686496825344  ...                         NaN\n",
              "14636  569587371693355008  ...                         NaN\n",
              "14637  569587242672398336  ...                         NaN\n",
              "14638  569587188687634433  ...  Eastern Time (US & Canada)\n",
              "14639  569587140490866689  ...                         NaN\n",
              "\n",
              "[14640 rows x 15 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZWJMV1dKmkB"
      },
      "source": [
        "Antes de começar a tratar os valores nulos e demais, podemos já excluir as colunas que não serão necessárias para nosso modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_swRHpMRKQzX"
      },
      "source": [
        "df = df_first.drop(['tweet_id', 'retweet_count', 'tweet_coord', 'tweet_created', 'tweet_location', 'name', 'user_timezone'], axis = 1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "gyfTqAwrL6De",
        "outputId": "3246de70-dc33-4dd3-dd4f-42172d73e01f"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6837</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  airline_sentiment  ...                                               text\n",
              "0           neutral  ...                @VirginAmerica What @dhepburn said.\n",
              "1          positive  ...  @VirginAmerica plus you've added commercials t...\n",
              "2           neutral  ...  @VirginAmerica I didn't today... Must mean I n...\n",
              "3          negative  ...  @VirginAmerica it's really aggressive to blast...\n",
              "4          negative  ...  @VirginAmerica and it's a really big bad thing...\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3R3uUBV1MNN6"
      },
      "source": [
        "Ao analisar o dataset, temos três sentimentos que serão analisados: positivos, negativos e neutros. Sendo que aqueles que deram notas negativas, têm a justificativa na coluna \"negativereason\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-8jFtRoL79N"
      },
      "source": [
        "df['negativereason'] = df['negativereason'].fillna('')\n",
        "df['negativereason_confidence'] = df['negativereason_confidence'].fillna('')\n",
        "df['airline_sentiment_gold'] = df['airline_sentiment_gold'].fillna('')\n",
        "df['negativereason_gold'] = df['negativereason_gold'].fillna('')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ol6pBQdtOB3H",
        "outputId": "e710940e-6bec-43ad-8d0c-3f0956cf531d"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14640, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "Ne1rI9cwOEe6",
        "outputId": "cb432061-2384-4561-fc63-ec6c94983d79"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Virgin America</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6837</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Virgin America</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  airline_sentiment  ...                                               text\n",
              "0           neutral  ...                @VirginAmerica What @dhepburn said.\n",
              "1          positive  ...  @VirginAmerica plus you've added commercials t...\n",
              "2           neutral  ...  @VirginAmerica I didn't today... Must mean I n...\n",
              "3          negative  ...  @VirginAmerica it's really aggressive to blast...\n",
              "4          negative  ...  @VirginAmerica and it's a really big bad thing...\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZ-_Hdn2OGH8"
      },
      "source": [
        "def Clean_Text(Texto):\n",
        "\n",
        "  if Texto:\n",
        "    Texto = contractions.fix(Texto)\n",
        "\n",
        "    Texto = ' '.join(Texto.split('.'))\n",
        "\n",
        "    Texto = re.sub(r'\\s+', ' ',\n",
        "                   re.sub('[^A-Za-z0-9]', ' ',\n",
        "                          Texto.strip().lower())).strip()\n",
        "\n",
        "    Texto = re.sub(r'\\W+', ' ', Texto.strip().lower()).strip()\n",
        "\n",
        "    Texto = [Palavra for Palavra in Texto.split()]\n",
        "\n",
        "    return Texto\n",
        "\n",
        "\n",
        "df['text'] = df['text'].apply(lambda Linha : ' '.join(Clean_Text(Linha)))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qVU4YVVW2SI",
        "outputId": "736e57f0-b5dd-4ca6-e988-cad935db63f3"
      },
      "source": [
        "nltk.download(['names', 'stopwords', 'vader_lexicon'])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package names to /root/nltk_data...\n",
            "[nltk_data]   Package names is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bn57BmWJXhHy",
        "outputId": "c1b27ed8-2d2f-46ee-c336-fb42eeccca22"
      },
      "source": [
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "Função_SIA = SentimentIntensityAnalyzer()\n",
        "\n",
        "print('I hate chocolate: ', Função_SIA.polarity_scores('I hate chocolate'), '\\n')\n",
        "print('I love chocolate: ', Função_SIA.polarity_scores('I love chocolate'), '\\n')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I hate chocolate:  {'neg': 0.787, 'neu': 0.213, 'pos': 0.0, 'compound': -0.5719} \n",
            "\n",
            "I love chocolate:  {'neg': 0.0, 'neu': 0.192, 'pos': 0.808, 'compound': 0.6369} \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zM3WP41nXhjH"
      },
      "source": [
        "Textos = df['text'].tolist()"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwfydOiAbpXu"
      },
      "source": [
        "Scores_Negativos = []\n",
        "Scores_Neutros = []\n",
        "Scores_Positivos = []\n",
        "Combinacao_Scores = []\n",
        "Final = []\n",
        "\n",
        "\n",
        "for Frases in Textos:\n",
        "  Score_Emocao = Função_SIA.polarity_scores(Frases)\n",
        "\n",
        "  Scores_Negativos.append(Score_Emocao['neg'])\n",
        "  Scores_Positivos.append(Score_Emocao['pos'])\n",
        "  Scores_Neutros.append(Score_Emocao['neu'])\n",
        "  Combinacao_Scores.append(Score_Emocao['compound'])\n",
        "  if Score_Emocao['compound'] > 0:\n",
        "    Final.append('positive')\n",
        "\n",
        "  elif Score_Emocao['compound'] < 0:\n",
        "    Final.append('negative')\n",
        "  else:\n",
        "    Final.append('neutral')"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtbyXqpBcQJ0"
      },
      "source": [
        "df['negative_score'] = Scores_Negativos\n",
        "df['positive_score'] = Scores_Positivos\n",
        "df['neutral_score'] = Scores_Neutros\n",
        "df['compound_score'] = Combinacao_Scores\n",
        "df['Final'] = Final"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "XyTmDNTGgVKH",
        "outputId": "b0da097f-1f02-4e06-aa64-563a54617734"
      },
      "source": [
        "# Avaliação de como ficou o processo:\n",
        "\n",
        "df[['text','negative_score', 'positive_score', 'neutral_score', 'compound_score', 'Final']].head(20)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>negative_score</th>\n",
              "      <th>positive_score</th>\n",
              "      <th>neutral_score</th>\n",
              "      <th>compound_score</th>\n",
              "      <th>Final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>virginamerica what dhepburn said</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>virginamerica plus you have added commercials ...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>virginamerica i did not today must mean i need...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>virginamerica it is really aggressive to blast...</td>\n",
              "      <td>0.216</td>\n",
              "      <td>0.123</td>\n",
              "      <td>0.661</td>\n",
              "      <td>-0.2716</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>virginamerica and it is a really big bad thing...</td>\n",
              "      <td>0.296</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.704</td>\n",
              "      <td>-0.5829</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>virginamerica seriously would pay 30 a flight ...</td>\n",
              "      <td>0.238</td>\n",
              "      <td>0.069</td>\n",
              "      <td>0.693</td>\n",
              "      <td>-0.5945</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>virginamerica yes nearly every time i fly vx t...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.172</td>\n",
              "      <td>0.828</td>\n",
              "      <td>0.4019</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>virginamerica really missed a prime opportunit...</td>\n",
              "      <td>0.142</td>\n",
              "      <td>0.175</td>\n",
              "      <td>0.683</td>\n",
              "      <td>0.1458</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>virginamerica well i did not but now i do d</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.205</td>\n",
              "      <td>0.795</td>\n",
              "      <td>0.1406</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>virginamerica it was amazing and arrived an ho...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.340</td>\n",
              "      <td>0.660</td>\n",
              "      <td>0.7717</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>virginamerica did you know that suicide is the...</td>\n",
              "      <td>0.359</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.641</td>\n",
              "      <td>-0.8555</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>virginamerica i lt 3 pretty graphics so much b...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.444</td>\n",
              "      <td>0.556</td>\n",
              "      <td>0.7490</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>virginamerica this is such a great deal alread...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.151</td>\n",
              "      <td>0.849</td>\n",
              "      <td>0.6249</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>virginamerica virginmedia i am flying your fab...</td>\n",
              "      <td>0.116</td>\n",
              "      <td>0.140</td>\n",
              "      <td>0.744</td>\n",
              "      <td>0.1531</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>virginamerica thanks</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.744</td>\n",
              "      <td>0.256</td>\n",
              "      <td>0.4404</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>virginamerica sfo pdx schedule is still mia</td>\n",
              "      <td>0.268</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.732</td>\n",
              "      <td>-0.2960</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>virginamerica so excited for my first cross co...</td>\n",
              "      <td>0.169</td>\n",
              "      <td>0.070</td>\n",
              "      <td>0.761</td>\n",
              "      <td>-0.5566</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>virginamerica i flew from nyc to sfo last week...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.094</td>\n",
              "      <td>0.906</td>\n",
              "      <td>0.4019</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>i flying virginamerica</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>virginamerica you know what would be amazingly...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.363</td>\n",
              "      <td>0.637</td>\n",
              "      <td>0.7902</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 text  ...     Final\n",
              "0                    virginamerica what dhepburn said  ...   neutral\n",
              "1   virginamerica plus you have added commercials ...  ...   neutral\n",
              "2   virginamerica i did not today must mean i need...  ...   neutral\n",
              "3   virginamerica it is really aggressive to blast...  ...  negative\n",
              "4   virginamerica and it is a really big bad thing...  ...  negative\n",
              "5   virginamerica seriously would pay 30 a flight ...  ...  negative\n",
              "6   virginamerica yes nearly every time i fly vx t...  ...  positive\n",
              "7   virginamerica really missed a prime opportunit...  ...  positive\n",
              "8         virginamerica well i did not but now i do d  ...  positive\n",
              "9   virginamerica it was amazing and arrived an ho...  ...  positive\n",
              "10  virginamerica did you know that suicide is the...  ...  negative\n",
              "11  virginamerica i lt 3 pretty graphics so much b...  ...  positive\n",
              "12  virginamerica this is such a great deal alread...  ...  positive\n",
              "13  virginamerica virginmedia i am flying your fab...  ...  positive\n",
              "14                               virginamerica thanks  ...  positive\n",
              "15        virginamerica sfo pdx schedule is still mia  ...  negative\n",
              "16  virginamerica so excited for my first cross co...  ...  negative\n",
              "17  virginamerica i flew from nyc to sfo last week...  ...  positive\n",
              "18                             i flying virginamerica  ...   neutral\n",
              "19  virginamerica you know what would be amazingly...  ...  positive\n",
              "\n",
              "[20 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47ADwyI-hQcA",
        "outputId": "5c9a3f81-7503-47f8-c6e0-b7b4d750c19d"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.10.3-py3-none-any.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 39.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 68.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting huggingface-hub>=0.0.12\n",
            "  Downloading huggingface_hub-0.0.17-py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 35.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.17 pyyaml-5.4.1 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.10.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "4tl60dn6h1YL",
        "outputId": "d0486680-5153-4aac-b88e-9f5f2ba2dccd"
      },
      "source": [
        "# Iportamos a biblioteca transformers para fazer a mineração da emoção e avaliremos sua acurácia\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "Funcao_Classificacao = pipeline('sentiment-analysis')\n",
        "\n",
        "Funcao_Classificacao('i hate chocolate')[0]['label']"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'NEGATIVE'"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fLZzHh31oavn",
        "outputId": "4972328d-3125-492b-e30d-3681eb531ae7"
      },
      "source": [
        "Funcao_Classificacao('i love chocolate')[0]['label']"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'POSITIVE'"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Qxq9U5XnodO4",
        "outputId": "eaf1446e-d789-4a96-9f35-43c12ad7924b"
      },
      "source": [
        "Funcao_Classificacao('i dont like chocolate')[0]['label']"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'NEGATIVE'"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oBucHtyfo0EJ",
        "outputId": "ae16e4e1-4bc0-41c7-96e1-5b57bd07a802"
      },
      "source": [
        "Funcao_Classificacao('i really love airplanes')[0]['label']"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'POSITIVE'"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBn-7AJSo7tZ"
      },
      "source": [
        "Após a tratativa e aplicação dos modelos das próprias bibliotecas, foi possível fazer a análise de sentimentos de posts do Twitter.\n",
        "Esta análise foi feita com os modelos das prórpias libs importadas. Poderíamos fazer também com qualquer dataset que coletarmos no Twitter, após o processo de ETL do arquivos que armazenamos em um banco de dados, filtrarmos os dados, transformarmos os arquivos json, assim teríamos a base inicial para trabalhar melhor. Após a transformação em df, fica mais fácil a utilização com o Pandas.\n",
        "Há também a possibilidade de fazer a implementação de análise de sentimentos em modelos em tempo real com o consumo da API, porém, exigiriam mais recursos, sendo necessária uma lib como o PySpark por exemplo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Qw-j91_quFo"
      },
      "source": [
        ""
      ]
    }
  ]
}